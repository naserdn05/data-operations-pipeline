# Data Operations Pipeline

This project simulates a real-world data operations workflow used by data teams.

The pipeline includes three main stages:

## 1. Data Ingestion
Loads raw customer data from a CSV file.

## 2. Data Validation
Checks for:
- Missing values
- Invalid formats
- Data consistency issues

## 3. Data Processing
Cleans and transforms the dataset:
- Removes duplicates
- Handles null values
- Standardizes column names
- Creates derived columns (total_price)

## Output
A clean dataset ready for analytics:
processed_customers.csv

## Technologies Used
- Python
- Pandas
- Data Quality Checks
- ETL Concepts

## Purpose
This project demonstrates practical skills required for Data Analyst / Data Operations roles, including data cleaning, validation, and transformation.
